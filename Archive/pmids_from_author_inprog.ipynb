{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b18b93-fa4a-4443-8c03-afa1a365f1d3",
   "metadata": {},
   "source": [
    "# Define Functions to Get PM(C)IDs and Openness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4cb65e-ed22-4175-8a28-0ab7b6e35ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from re import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f98f47b-c779-46a8-b5b0-1508b7606246",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed example:  (None, '2023')\n",
      "Open example:  ('PMC7612594', '2022')\n"
     ]
    }
   ],
   "source": [
    "# Get PMCID from PMID\n",
    "def get_pmcid_year(pmid):\n",
    "    base_url = f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\"\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    date = soup.find_all('span', {'class' : 'cit'})[0].text.strip()\n",
    "    date = split(\"\\D\",date)[0]\n",
    "    try:\n",
    "        pmcid = soup.find_all('a', {'class' : 'id-link', 'data-ga-action' : 'PMCID'})[0].text.strip()\n",
    "    except:\n",
    "        pmcid = None\n",
    "    return (pmcid , date)\n",
    "\n",
    "print(\"Closed example: \", get_pmcid_year(\"35770940\"))\n",
    "print(\"Open example: \", get_pmcid_year(\"35165460\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6e1addfc-0faf-4c51-820c-0a744c5bcc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jennifer:  ({'35770940': 'closed', '35944998': 'PMC9480892', '32321746': 'PMC7204083', '37540708': 'open'}, {'35770940': '2023', '35944998': '2022', '32321746': '2020', '37540708': '2023'})\n",
      "Emily L:  ({'36792646': 'PMC9932154', '36582611': 'PMC9792983', '33906174': 'PMC8504120'}, {'36792646': '2023', '36582611': '2022', '33906174': '2021'})\n",
      "Arpy:  ({'30471926': 'PMC6655561', '30096299': 'PMC6447408', '34197733': 'PMC8376805', '32999462': 'PMC7957574', '29632380': 'PMC5896795', '26220313': 'PMC4584188', '26131660': 'PMC4545963', '22660328': 'PMC3367801', '36384944': 'PMC9668842', '33230336': 'closed', '26551563': 'PMC4716836', '32613945': 'PMC7360370', '25723967': 'PMC4371381', '26905595': 'PMC4764347', '25739505': 'PMC4425585', '21825165': 'PMC3174680', '28384468': 'PMC5439268', '22866029': 'PMC3406316', '19056989': 'closed', '23403489': 'PMC3566411', '22325203': 'PMC3278709', '26104011': 'closed'}, {'30471926': '2019', '30096299': '2018', '34197733': '2021', '32999462': '2020', '29632380': '2018', '26220313': '2016', '26131660': '2015', '22660328': '2012', '36384944': '2022', '33230336': '2020', '26551563': '2015', '32613945': '2020', '25723967': '2015', '26905595': '2016', '25739505': '2015', '21825165': '2011', '28384468': '2017', '22866029': '2012', '19056989': '2008', '23403489': '2013', '22325203': '2012', '26104011': '2015'})\n"
     ]
    }
   ],
   "source": [
    "# Get list of PMIDs from author name\n",
    "def get_pmids_open(author):\n",
    "    \n",
    "    # Parse author name, build first+last\n",
    "    author = author.split()\n",
    "    if len(author) > 1:\n",
    "        aname = author[0]\n",
    "        for name in author[1:]:\n",
    "            aname += \"+\" + name\n",
    "    else:\n",
    "        aname = author[0]\n",
    "        \n",
    "    #find total number of pages\n",
    "    base_url= f'https://pubmed.ncbi.nlm.nih.gov/?term={aname}&page='\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    pages = soup.find_all('label', {'class' : 'of-total-pages'})\n",
    "    p = pages[0].text.strip()\n",
    "    p = p.split()\n",
    "    pagenum=int(p[1])\n",
    "    \n",
    "    # scrape pubmed\n",
    "    pmids = []\n",
    "    entries = []\n",
    "    for i in range(1,pagenum+1): #change # into max num of pages\n",
    "        URL = f'https://pubmed.ncbi.nlm.nih.gov/?term={aname}&page={i}'\n",
    "        response = requests.get(URL)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        pmids += soup.find_all('span', {'class' : 'docsum-pmid'})\n",
    "        entries += soup.find_all(\"div\", class_='docsum-content')\n",
    "    \n",
    "    # build dictionary of id:pmcid\n",
    "    ids = {}\n",
    "    years = {}\n",
    "    for id,entry in zip(pmids,entries):\n",
    "        pmcid, year = get_pmcid_year(id.text.strip())\n",
    "        years[id.text.strip()] = year\n",
    "        if pmcid:\n",
    "            ids[id.text.strip()] = pmcid\n",
    "        elif search(r\"Free\",entry.text.strip()): # use regex to search for \"Free\" in docsum-content\n",
    "            ids[id.text.strip()] = \"open\"\n",
    "        else:\n",
    "            ids[id.text.strip()] = \"closed\"\n",
    "        \n",
    "    return ids, years\n",
    "\n",
    "print(\"Jennifer: \", get_pmids_open(\"jennifer jahncke\"))\n",
    "print(\"Emily L: \", get_pmids_open(\"emily lecy\"))\n",
    "print(\"Arpy: \", get_pmids_open(\"arpiar saunders\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9e2f751d-3348-4eca-97f9-c4e5c57d2476",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7037037037037037\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>code</th>\n",
       "      <th>full_text</th>\n",
       "      <th>pmid</th>\n",
       "      <th>year</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35165460</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28618073</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32364583</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34866633</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33296680</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34270947</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29979149</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29628374</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28542521</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  code  full_text      pmid  year     Score\n",
       "0   0.0   NaN        1.0  35165460  2022  0.500000\n",
       "1   NaN   NaN        1.0  28618073  2017  1.000000\n",
       "2   1.0   1.0        1.0  32364583  2020  1.000000\n",
       "3   NaN   NaN        0.0  34866633  2021  0.000000\n",
       "4   1.0   NaN        1.0  33296680  2021  1.000000\n",
       "5   0.0   1.0        1.0  34270947  2021  0.666667\n",
       "6   1.0   1.0        1.0  29979149  2018  1.000000\n",
       "7   0.0   1.0        1.0  29628374  2018  0.666667\n",
       "8   0.0   NaN        1.0  28542521  2017  0.500000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_openness(author, api):\n",
    "    ids, years = get_pmids_open(author)\n",
    "    \n",
    "    apikey = open(api, 'r').read()\n",
    "    \n",
    "  # Load keywords and create open-science categories\n",
    "    keyword_df = pd.read_csv('keywords.csv')\n",
    "    categoryIDs = np.unique(np.array(keyword_df['category']))\n",
    "    category_descriptions = keyword_df['category_description']\n",
    "    category_descriptions = category_descriptions.unique().tolist()\n",
    "    full_text = 'full_text'\n",
    "    category_descriptions.append(full_text)\n",
    "    \n",
    "    #create df with all the unique categories:\n",
    "    #data = [[None] * len(ids) for _ in range(len(category_descriptions))]\n",
    "    data = (len(ids), len(category_descriptions))\n",
    "\n",
    "    #data = (len(ids), len(category_descriptions))\n",
    "    o_idx_df = pd.DataFrame(np.zeros(data), columns = category_descriptions)\n",
    "    #deleting the 'code relevant column from the final df\n",
    "    pmcids = []\n",
    "    for i, item in enumerate(ids): \n",
    "        o_idx_df.loc[[i],['pmid']] = item\n",
    "        o_idx_df.loc[[i],['year']] = years[item]\n",
    "        if ids[item] == 'closed':\n",
    "            pmcids.append(None)\n",
    "            #if PMCID is unavailable make items in df None type\n",
    "            o_idx_df.iloc[[i],0:2] = None\n",
    "            continue\n",
    "        if ids[item] == 'open':\n",
    "            pmcids.append(None)\n",
    "            o_idx_df.loc[[i],['full_text']] = 1\n",
    "            o_idx_df.iloc[[i],0:2] = None\n",
    "\n",
    "        else:\n",
    "            pmcids.append(ids[item])\n",
    "            o_idx_df.loc[[i],['full_text']] = 1\n",
    "    db = 'pmc'\n",
    "    base = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?'\n",
    "    for j, pmcid in enumerate(pmcids):\n",
    "        if pmcid == None:\n",
    "            continue\n",
    "        s = '{:s}db={:s}&id={:s}'.format(base, db, pmcid, apikey)\n",
    "        out = requests.get(s)\n",
    "        bs = BeautifulSoup(out.content, features=\"xml\")\n",
    "        # Check if full text is available; if not - move to the next paper\n",
    "        for cat in categoryIDs:\n",
    "            found_keyword = False\n",
    "            # Loop through specific keywords related to each open-science category\n",
    "            for k, keyword in enumerate(keyword_df['keyword'][keyword_df['category'] == cat]):\n",
    "                for s in finditer(keyword, out.text, IGNORECASE):\n",
    "                    #if we are on cat \"code relevant\" (cat 3) we are testing to see if code is relevant for this paper\n",
    "                    o_idx_df.iloc[[j],[cat-1]] = keyword_df.loc[k][\"weight\"]\n",
    "                    found_keyword = True\n",
    "\n",
    "                # If one keyword is found, stop with searching for this category\n",
    "                if found_keyword is True:\n",
    "                    break\n",
    "            #if code category is 0, check to see if code is relevant\n",
    "            if cat == 2 and found_keyword== True:\n",
    "                break \n",
    "            if cat == 3 and found_keyword == False:\n",
    "                o_idx_df.iloc[[j],[cat-2]] = None\n",
    "                break    \n",
    "                \n",
    "    del o_idx_df['code_relevant']\n",
    "        \n",
    "    o_idx_df.loc[:,'Score'] = o_idx_df.mean(numeric_only=True, axis=1)\n",
    "   \n",
    "    OIndex=o_idx_df[\"Score\"].mean()\n",
    "    print(OIndex)\n",
    "\n",
    "    return o_idx_df\n",
    "\n",
    "def oindex(df):\n",
    "    OIndex = df[\"o-score\"].mean()\n",
    "    \n",
    "    \n",
    "\n",
    "get_openness(\"jason early\", \"../apikey.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
